# Mejora y prueba de modelos de Machine Learning

La forma en que entrenamos los datos no es un proceso totalmente automatizado.
Confiar ciegamente en esto puede llevarlos a apendder cosas que no resulten utiles.


**Escenario: entrenamiento de perros de rescate en avalanchas**
Ha llegado el momento de entrenar a una nueva generación de perros en la búsqueda de excursionistas que han sido arrastrados por avalanchas. Existe un debate en la oficina sobre qué perros son los mejores: ¿es mejor un perro grande que un perro más pequeño? ¿Los perros se deben entrenar cuando sean pequeños o cuando sean más mayores? Afortunadamente, cuenta con estadísticas sobre los rescates realizados en los últimos años que puede consultar. Sin embargo, el entrenamiento de perros resulta caro: debe asegurarse de que los criterios de selección de perros sean seguros.


## Normalizacion y estandarizacion
El escalado es una tecnica que cambia el intervalo de valores que tiene una caracteristica.
Esto le permite a los modelos aprender de forma mas rapida y solida.

### Normalizacion frente a estandarizacion
* Normalizacion: Es modificar la escala de los valores para que todos se ajusten a un intervalo determinado (0 y 1).

* Estandarizacion: Le resta la media de los valores y luego se divide por la desviacion estandar.


### ¿Por que es necesario modificar la escala?
Entenderemos esto con un ejemplo.
Supongamos que queremos entrenar un modelo para predecir si un perro trabajará correctamente en la nieve. Los datos se muestran a continuación como puntos y la línea de tendencia que intentamos encontrar se muestra como una línea sólida:

[](https://learn.microsoft.com/es-es/training/modules/test-machine-learning-models/media/2-normalization-graph.png)


#### El escalado proporciona un mejor punto de partida para el aprendizaje
La línea óptima anterior tiene dos parámetros: la intersección, que es 50, y la línea en x=0 y la pendiente, que es 0,01; cada 1000 milímetros aumenta los rescates en 10. Supongamos que comenzamos el entrenamiento con estimaciones iniciales de 0 para ambos parámetros.

Si nuestras iteraciones de entrenamiento modifican los parámetros en torno a 0,01 por iteración de media, se necesitarán al menos 5000 iteraciones antes de encontrar la intersección: 50/0,01 = 5000 iteraciones. La estandarización puede acercar esta intersección óptima a cero, lo que significa que se puede identificar mucho más rápido. Por ejemplo, si restamos la media de nuestra etiqueta (rescates anuales) y nuestra característica (altura), la intersección es -0,5, en lugar de 50, de modo que podremos encontrarla unas 100 veces más rápido.

[](https://learn.microsoft.com/es-es/training/modules/test-machine-learning-models/media/2-normalization-graph-2.png)

Hay otras razones por las que los modelos complejos pueden ser muy lentos de entrenar cuando la suposición inicial está lejos de la marca, pero la solución sigue siendo la misma: desplazar las características a algo más cercano a la suposición inicial.


#### La estandarización permite que los parámetros se entrenen a la misma velocidad

En los datos recién desplazados, tenemos un desplazamiento ideal de -0,5 y una pendiente ideal de 0,01. Aunque el desplazamiento ayuda a acelerar las cosas, sigue siendo mucho más lento entrenar el desplazamiento que entrenar la pendiente. Esto puede ralentizarlo todo y hacer que el entrenamiento sea inestable.

Por ejemplo, nuestras suposiciones iniciales de desplazamiento y pendiente son cero. Si cambiamos los parámetros en aproximadamente 0,1 en cada iteración, encontraremos el desplazamiento rápidamente, pero será muy difícil encontrar la pendiente correcta, ya que los aumentos de pendiente serán demasiado grandes (0 + 0,1 > 0,01) y pueden sobrepasar el valor ideal. Podemos reducir los ajustes, pero esto ralentizará el tiempo que se tarda en encontrar la intersección.

¿Qué ocurre si escalamos nuestra característica de altura?

[](https://learn.microsoft.com/es-es/training/modules/test-machine-learning-models/media/2-normalization-graph-3.png)

La pendiente de la línea ahora es 0,5. Preste atención al eje x. Nuestra intersección óptima de -0,5 y la pendiente de 0,5 son de la misma escala. Ahora es fácil elegir un tamaño de paso razonable, que es la rapidez con la que el descenso de gradiente actualiza los parámetros.

**El escalado ayuda con varias caracteristicas**
Tener las caracteristicas en escalas diferentes puede provocar problemas de ajuste.

### ¿Siempre es necesario escalar?
No siempre, algunos modelos pueden ajustarse sin ningun modelo iterativo.
Los modelos suelen realizar escalado automatico de caracteristicas.


## Conjunto de datos de prueba y entrenamiento
El cojunto de datos que usamos para entrenar un modelo se denomina "cojunto de datos de entrenamiento" y puede ser diferente a los datos del mundo real.

### ¿Que es el sobreajuste?
Un modelo se sobreajusta si funciona mejor con los datos de entrenamiento que con otros datos.


### ¿Como puedo evitar el sobreajuste?
El sobreajuste se puede evitar con un modelo mas sencillo o usando un conjunto de datos que sea una representacion mejorada de lo que se ve en el mundo real.

Considere un escenario que los datos reales tengan este aspecto.

[datos reales](https://learn.microsoft.com/es-es/training/modules/test-machine-learning-models/media/4-overfitting-graph.png)


Sin embargo, sopongamos que recopilamos informacion sobre 5 perros y la usamos como conjunto de datos de entrenamiento para ajustar una linea compleja.

[datos](https://learn.microsoft.com/es-es/training/modules/test-machine-learning-models/media/4-overfitting-graph-2.png)

Pero cuando se aplique a datos del mundo real las prediccion seran incorrectas.

[datos del mundo real](https://learn.microsoft.com/es-es/training/modules/test-machine-learning-models/media/4-overfitting-graph-3.png)

Sin embargo, si tuvieramos un conjunto de datos representativos, no solo 5, y un modelo mas sencillo la linea en que nos ajustamos haria mejores predicciones.

[Nuevo modelo](https://learn.microsoft.com/es-es/training/modules/test-machine-learning-models/media/4-overfitting-graph-4.png)

Otra manera de evitar el sobreajuste es detener el entrenamiento despues que el modelo haya aprendido las reglas generales.

### ¿Que es un conjunto de datos de prueba?
Conocido tambien como datos de validacion.
Los conjuntos de datos de prueba se crean tomando un conjunto de datos grandes y dividiendolo.
Una parte es el conjunto de datos de entrenamiento y el otro el de prueba.
El cojunto de datos de prueba sirve para comprobar el funcionamiento del modelo.

### De acuerdo, pero¿de que sirve esto?
El conjunto de datos sirve para dos cosas:
* Si el rendimiento de las pruebas deja de mejorar durante el entrenamiento, podemos detenernos, sino se da un sobreajuste.
* Usamos el conjunto de datos de prueba despues del entrenamiento.

### ¿Que significa eso para las funciones de costo?
Cuando tenemos conjuntos de datos de entrenamiento y prueba, terminamos calculando dos funciones de costo.

* La primera, es al utilizar los datos de entrenamiento, se proporciona al optimizador y se usa para entrenar el modelo.

* La segunda, se calcula mediante el conjunto de datos de prueba, se usa para comprobar el funcionamiento del modelo.
Para calcularlo, pausamos el entrenamiento, observamos el rendimiento del modelo y luego reanudamos el entrenamiento.


## Matices de los conjuntos de pruebas

### Los conjuntos de pruebas pueden ser engañosos
Estos conjuntos de prueba puede proporcionarnos una confianza falsa si son muy pequeños y no representen la variedad de datos del mundo real.

### Los conjuntos de pruebas no son gratuitos
Entre mas datos, menor posibilida de que el modelo se sobreajuste. Entre mas grande mas confianza tenemos en los resultados.
Los conjuntos de pruebas van de un 10% al 50% de los datos.


### Entrenar y probar no es el unico enfoque
Merece la pena tener en cuenta que el enfoque de entrenar y probar es habitual, pero no es el único que se utiliza. Dos de las alternativas más comunes son el enfoque de exclusión y los métodos estadísticos.

**El enfoque de exclusion**: Es como entrenar y probar, pero en lugar de dividir entre dos, se divide entre  3, entrenamiento, prueba o validacion y espera.
El conjunto de datos de exclusion es un tipo de cojunto de datos de pruebas que se usa solo una vez, cuando estamos listos para implementar nuestro modelo para su uso real.

La idea de un tercer conjunto de datos es que también podemos probarlo. Este enfoque significa dividir los datos de tres maneras, lo que implica que empezamos con incluso menos datos de entrenamiento. Si no tenemos muchos datos con los que trabajar, este enfoque puede reducir nuestra capacidad de obtener un buen modelo.

**Enfoques estadisticos**:

Los modelos más sencillos que se han originado en las estadísticas a menudo no necesitan conjuntos de datos de prueba. En cambio, el grado de sobreajuste del modelo puede calcularse directamente como significación estadística: un "valor p".

Estos métodos estadísticos son eficaces, están bien establecidos y forman la base de la ciencia moderna. La ventaja es que el conjunto de entrenamiento no tiene que dividirse nunca y obtenemos una comprensión mucho más precisa de la confianza que podemos tener sobre un modelo. Por ejemplo, un valor p de 0,01 significa que hay una probabilidad muy pequeña de que nuestro modelo haya encontrado una relación que realmente no exista en el mundo real. Por el contrario, un valor p de 0,5 significa que, aunque nuestro modelo podría ser bueno con nuestros datos de entrenamiento, no será mejor que lanzar una moneda al aire en el mundo real.

El inconveniente de estos enfoques es que solo se aplican fácilmente a determinados tipos de modelos, como los modelos de regresión lineal con los que hemos estado trabajando. Para todos los modelos, salvo los más sencillos, estos cálculos pueden ser extremadamente complejos de realizar correctamente, por lo que están fuera del alcance de este curso. También sufren la misma limitación con respecto a la selección de datos: si nuestros datos de entrenamiento están sesgados, nuestros valores p serán engañosos.