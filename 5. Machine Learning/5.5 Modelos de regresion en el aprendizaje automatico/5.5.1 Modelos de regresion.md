# Aprendizaje y conocimiento de los modelos de regresión en el aprendizaje automático

## Introduccion
La regresion, tambien conocido como "ajustar la linea de tendencia" es una tecnica de analisis de datos sencilla, comun y muy util.
Esta identifica la intensidad de la relacion entre una o varias caracteristicas y una sola etiqueta.

**Escenario: saturación de una clínica veterinaria**

A lo largo de este módulo, usaremos el siguiente escenario de ejemplo para explicar los conceptos subyacentes a la regresión. Este escenario está diseñado para proporcionar un ejemplo de cómo podría usar esta técnica al analizar datos futuros.

Los perros de rescate de la organización benéfica que administra han sufrido una repentina ola de enfermedad. Después de un día de entrenamiento y actividades sociales, muchos de los perros con los que trabaja han enfermado, siendo la fiebre el síntoma principal (temperatura corporal elevada). Preocupados por los perros que aún no han presentado síntomas, el equipo ha recopilado información básica sobre los primeros 100 perros que enfermaron. Su trabajo es identificar cuáles de ellos tienen mayor riesgo de enfermar, de modo que los pueda visitar un veterinario.

## ¿Que es la regresion?
Es una tenica de analisis de datos conocida como "ajustar una linea", donde se ajusta a la linea recta entre una variable(caracteristica) y otra (etiqueta)

### Regresion Lineal Simple
Modela una relacion lineal entre una sola caracteristica y una etiqueta.

[](https://learn.microsoft.com/es-es/training/modules/understand-regression-machine-learning/media/2-simple-linear-regression.png)

Tiene dos parametros, una interseccion (c) que indica el valor de la etiqueta cuando la caracteristica se establece en cero y una pendiente (m) que indica cuanto aumentara la etiqueta para cada aumento de un punto de la caracteristica.

y = mx+c

Donde y es la etiqueta y x la caracteristica.

Ejemplo: En nuestro escenario seria.
Temperatura = m*edad + c
Debe buscar los valores de "m" y "c" durante el procedimiento de ajuste. Si resulta que m = 0,5 y c = 37, es posible que lo visualicemos de la siguiente forma:

[](https://learn.microsoft.com/es-es/training/modules/understand-regression-machine-learning/media/2-linear-graph.png)

Esto significaría que cada año de edad está asociado con un aumento de la temperatura corporal de 0,5 °C, con un punto inicial de 37 °C.

#### Ajuste de la regresion lineal.
Normalmente, usamos bibliotecas existentes para ajustarnos a los modelos de regresión. La regresión normalmente pretende encontrar la línea que genera la menor cantidad de error, donde el error significa la diferencia entre el valor del punto de datos real y el valor previsto


Por ejemplo, en la imagen siguiente, la línea negra indica el error entre la predicción, la línea roja y un valor real: el punto.

[](https://learn.microsoft.com/es-es/training/modules/understand-regression-machine-learning/media/2-fitting-linear-regression.png)

Al mirar estos dos puntos en un eje Y, podemos ver que la predicción era 39,5, pero el valor real era 41.

[](https://learn.microsoft.com/es-es/training/modules/understand-regression-machine-learning/media/2-fitting-linear-regression.2.png)

Por lo tanto, el modelo estaba equivocado en 1,5 para este punto de datos.

Por lo tanto, el modelo estaba equivocado en 1,5 para este punto de datos.

Normalmente, ajustamos un modelo minimizando la suma residual de cuadrados. Esto significa que la función de costo se calcula de la siguiente manera:

    * Calcular la diferencia entre los valores reales y previstos (como los anteriores) para cada punto de datos
    * Eleve estos valores al cuadrado
    * Suma (o promedio) de estos valores al cuadrado

El paso de elevar al cuadrado significa que no todos los puntos contribuyen uniformemente a la línea: los valores atípicos, que son puntos que no se encuentran en el patrón esperado, tienen un error desproporcionadamente mayor, lo que puede influir la posición de la línea.

#### Puntos fuertes de la regresion
* Predecible y facil de interpretar, debido a que las escuaciones que se describen son simples.
* Facil de extrapolar, es facil realizar predicciones para valores fuera del intervalo de nuestro conjunto de datos.
* Normalmente, se garantiza un ajuste optimo, Usa la suma de cuadrados.

## Regresion Lineal Multiple y R cuadrado

### Regresion Lineal Multiple
Modela la relacion entre varias caracteristicas y una sola etiqueta.
Es lo mismo que la regresion simple y se ajusta con la misma funcion de costo, pero con mas caracteristicas.

Modela simultaneamente varias relaciones independientes entre si.

Por ejemplo, si predecimos cuán enfermo se pone un perro en función de age y body_fat_percentage, se encuentran dos relaciones:

Cómo age aumenta o reduce la posibilidad de enfermedad
Cómo body_fat_percentage aumenta o reduce la posibilidad de enfermedad

Si solo estamos trabajando con dos características, podemos visualizar nuestro modelo como una superficie 2D plana

#### La regresion lineal mutiple tiene suposiciones
El hecho que el modelo espera que las caracteristicas sean independientes se denomina *Suposicion de modelo*
Cuando las suposiciones no son verdaderas el modelo produce predicciones erroneas.

Por ejemplo, la edad probablemente pronostica cuán enfermos se ponen los perros, puesto que los perros con más edad se enferman con más facilidad, igual que saber si a los perros se les ha enseñado a jugar al frisbi: todos los perros de más edad probablemente saben cómo jugar al frisbi. Si incluyéramos age y knows_frisbee en nuestro modelo como características, es probable que el resultado sería que knows_frisbee es un buen indicador de enfermedad y age se subestima. Esto es un poco absurdo porque saber jugar a frisbi seguramente no causa enfermedades. Por el contrario, dog_breed puede también ayudarnos a predecir enfermedades, pero no hay ninguna razón para pensar que age predice dog_breed, por lo que podríamos incluirlos en un solo modelo.


### Bondad de Ajuste R2
Este es un valor entre 0 y 1 que nos indica como se ajusta un modelo de regresion lineal a los datos.

Cuando se habla de que las correlaciones son solidas, quiere decir que R2 es grande

Ejercicio anterior en el que analizamos la relación entre age y core_temperature. Un R2 de 1 significaría que se podrían usar años para predecir perfectamente quién tenía temperatura alta y quién la tenía baja. Por el contrario, un 0 significaría simplemente que no había ninguna relación entre los años y la temperatura.

[](https://learn.microsoft.com/es-es/training/modules/understand-regression-machine-learning/media/4-goodness-of-fit-graph.png)

La realidad está en algún lugar intermedio. Nuestro modelo podría predecir la temperatura hasta cierto grado (por lo que es mejor que R2 = 0), pero los puntos variaron ligeramente de esta predicción (por lo que es menor que R2 = 1).

Los valores de R2 se aceptan ampliamente, pero no son una medida perfecta que podamos usar de forma aislada. Estos valores sufren cuatro limitaciones:

* Debido a como se calcula R2, cuantas mas muestras tenemos, mayor sera el R2.
* Los valores de R2 no nos dice como funcionara un modelo con datos nuevos y no vistos anteriormente.
* Los valores de R2 no nos dicen la direccion de la relacion.

## Regresion Polinomica

### ¿En que consiste la regresion polinomica?
Esta modela las relaciones como un tipo determinado de curva.
Entre mas parametros tenga la ecuacion(modelo) mas compleja puede ser la curva.

Ejemplo:
Un polinomio de dos parametros
y = interseccion + B1 *x

[](https://learn.microsoft.com/es-es/training/modules/understand-regression-machine-learning/media/6-polynomial-graph.png)

con tres parametros
y = intersección + B1 * x + B2 * x2
[](https://learn.microsoft.com/es-es/training/modules/understand-regression-machine-learning/media/6-three-parameter-polynomial.png)

y con cuatro
y = intersección + B1 * x + B2 * x2 + B3 * x3

[](https://learn.microsoft.com/es-es/training/modules/understand-regression-machine-learning/media/6-four-parameter-polynomial.png)

Una ventaja de la regresion polinomic es que puede usar para observar todo tipo de relaciones.

Por ejemplo, la regresión polinómica se puede usar para relaciones que son negativas dentro de un determinado intervalo de valores de características, pero positivas dentro de otras. También se puede usar cuando la etiqueta (valor y) no tiene ningún límite superior teórico.

[](https://learn.microsoft.com/es-es/training/modules/understand-regression-machine-learning/media/6-example-curves.png)


La desventaja es que se extrapolan de manera erronea, significa que no puede predecir fuera de su rango de datos.
Las curvas son faciles de sobreajustar, esto quiere decir que el ruido de los datos puede cambiar la forma de la curva.

[](https://learn.microsoft.com/es-es/training/modules/understand-regression-machine-learning/media/6-curve.png)

#### ¿Se pueden usar curvas con varias caracteristicas?

e pueden usar curvas de todo tipo para estas relaciones cuando corresponda. Aunque se debe tener cuidado de no usar curvas, como polinomios, con varias características donde no son necesarias. Esto se debe a que las relaciones pueden acabar siendo muy complejas, lo que dificulta comprender los modelos y evaluar si realizarán predicciones que no tienen sentido desde el punto de vista del mundo real.
